#!/usr/bin/env python3
"""Test script to measure end-to-end latency of the current system"""
import time
import redis
import json
import statistics

def measure_redis_latency():
    """Measure latency through Redis Streams"""
    r = redis.Redis(host='localhost', port=6379)
    
    latencies = []
    
    print("ðŸ“Š Measuring Redis Streams latency...")
    
    for i in range(100):
        # Read latest trade from Redis
        start_time = time.perf_counter()
        
        # Try to get latest trade from any stream
        streams = r.keys("trades:*")
        if streams:
            # Read from first available stream
            result = r.xrevrange(streams[0], count=1)
            if result:
                end_time = time.perf_counter()
                latency_ms = (end_time - start_time) * 1000
                latencies.append(latency_ms)
        
        time.sleep(0.01)  # 10ms between reads
    
    if latencies:
        avg_latency = statistics.mean(latencies)
        p50 = statistics.median(latencies)
        p95 = statistics.quantiles(latencies, n=20)[18] if len(latencies) > 20 else max(latencies)
        p99 = statistics.quantiles(latencies, n=100)[98] if len(latencies) > 100 else max(latencies)
        
        print(f"\nðŸ“ˆ Redis Streams Latency (current implementation):")
        print(f"   Samples: {len(latencies)}")
        print(f"   Average: {avg_latency:.2f}ms")
        print(f"   P50: {p50:.2f}ms")
        print(f"   P95: {p95:.2f}ms")
        print(f"   P99: {p99:.2f}ms")
        print(f"   Min: {min(latencies):.2f}ms")
        print(f"   Max: {max(latencies):.2f}ms")
    else:
        print("âŒ No data available in Redis Streams")

def check_shared_memory_stats():
    """Check shared memory performance"""
    import struct
    import mmap
    import os
    
    path = "/tmp/alphapulse_shm/trades"
    if not os.path.exists(path):
        print("âŒ Shared memory not available")
        return
        
    with open(path, "r+b") as f:
        mm = mmap.mmap(f.fileno(), 0)
        
        # Read header
        header_size = 232
        version, capacity = struct.unpack("II", mm[0:8])
        write_sequence = struct.unpack("Q", mm[8:16])[0]
        
        # Measure read latency
        latencies = []
        for i in range(100):
            start_time = time.perf_counter()
            
            # Read one trade
            index = (write_sequence - 1) % capacity
            trade_offset = header_size + (index * 128)
            trade_data = mm[trade_offset:trade_offset+128]
            
            end_time = time.perf_counter()
            latency_us = (end_time - start_time) * 1_000_000
            latencies.append(latency_us)
            
            time.sleep(0.001)  # 1ms between reads
        
        mm.close()
        
        if latencies:
            avg_latency = statistics.mean(latencies)
            p50 = statistics.median(latencies)
            p95 = statistics.quantiles(latencies, n=20)[18] if len(latencies) > 20 else max(latencies)
            
            print(f"\nâš¡ Shared Memory Read Latency (new implementation):")
            print(f"   Samples: {len(latencies)}")
            print(f"   Average: {avg_latency:.2f}Î¼s")
            print(f"   P50: {p50:.2f}Î¼s")
            print(f"   P95: {p95:.2f}Î¼s")
            print(f"   Min: {min(latencies):.2f}Î¼s")
            print(f"   Max: {max(latencies):.2f}Î¼s")
            
            print(f"\nðŸŽ¯ Improvement Factor:")
            print(f"   Shared Memory is {1000 / avg_latency:.0f}x faster than Redis!")

if __name__ == "__main__":
    print("ðŸ”¬ AlphaPulse Latency Comparison Test\n")
    print("=" * 50)
    
    # Test Redis latency
    measure_redis_latency()
    
    # Test shared memory latency
    check_shared_memory_stats()
    
    print("\n" + "=" * 50)
    print("âœ… Test complete!")